#
# export_weights.py
# Convert PyTorch .pth checkpoints to C header weight arrays for MambaLite-Micro.
#
# Copyright (c) 2025 MambaLite-Micro Authors
# Licensed under the MIT License.

import torch
import numpy as np

def write_array_to_header(f, name, array):
    shape = array.shape
    dims = len(shape)
    assert dims in [1, 2], f"Only 1D or 2D arrays supported, got {dims}D for {name}"

    if dims == 1:
        f.write(f"#define {name}_size {shape[0]}\n")
        f.write(f"const float {name}[{shape[0]}] = {{\n")
    elif dims == 2:
        f.write(f"#define {name}_rows {shape[0]}\n")
        f.write(f"#define {name}_cols {shape[1]}\n")
        f.write(f"const float {name}[{shape[0] * shape[1]}] = {{\n")

    flat = array.flatten()
    for i, val in enumerate(flat):
        f.write(f"    {val:.8f}f, ")
        if (i + 1) % 8 == 0:
            f.write("\n")
    f.write("\n};\n\n")

def export_pth_to_header(pth_path, output_header="mamba_weights.h"):
    state_dict = torch.load(pth_path, map_location="cpu")
    with open(output_header, "w") as f:
        f.write("/**\n")
        f.write(" * @file mamba_weights.h\n")
        f.write(" * @brief Auto-generated weight file for MambaLite-Micro.\n")
        f.write(" *\n")
        f.write(" * Copyright (c) 2025 MambaLite-Micro Authors\n")
        f.write(" * Licensed under the MIT License.\n")
        f.write(" *\n")
        f.write(" * Generated by export_weights.py from a PyTorch .pth checkpoint.\n")
        f.write(" * Do not edit manually.\n")
        f.write(" */\n\n")
        f.write("#ifndef MAMBA_WEIGHTS_H\n#define MAMBA_WEIGHTS_H\n\n")
        # Example fixed configs (adapt as needed)
        f.write("#define mamba_d_model 64\n")
        f.write("#define mamba_d_state 16\n")
        f.write("#define mamba_d_conv 4\n")
        f.write("#define mamba_expand 2\n")
        f.write("#define mamba_dt_min 0.001\n")
        f.write("#define mamba_dt_max 0.1\n")
        f.write("#define mamba_dt_scale 1.0\n")
        f.write("#define mamba_dt_rank 4\n")
        for name, tensor in state_dict.items():
            if name.endswith("conv1d.weight") and tensor.ndim == 3 and tensor.shape[1] == 1:
                tensor = tensor.squeeze(1)
            cname = f"{name.replace('.', '_')}"
            arr = tensor.detach().cpu().numpy().astype(np.float32)
            write_array_to_header(f, cname, arr)

        f.write("#endif // MAMBA_WEIGHTS_H\n")

if __name__ == "__main__":
    export_pth_to_header("path/to/model.pth", "path/to/output/mamba_weights.h")